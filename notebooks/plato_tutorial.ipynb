{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plato Tutorial\n",
    "\n",
    "[Plato](https://github.com/petered/plato) is a python package built on top of [Theano](http://deeplearning.net/software/theano/) with two objectives:  \n",
    "1) Simplify the use of Theano.  \n",
    "2) Build a good libary of standard Deep Learning algorithms.\n",
    "\n",
    "This tutorial takes you throught the Plato API.  It's useful but not necessary to have a basic knowledge of Theano to do this tutorial.\n",
    "\n",
    "## Contents:\n",
    "1. <a href=\"#symbolic-functions\">Symbolic Functions</a>\n",
    "1. <a href=\"#adding-state\">Adding State</a>\n",
    "1. <a href=\"#classes\">Classes</a> (Jump to here for a quick example of Regression in Plato) \n",
    "1. <a href=\"#callable-classes\">Callable Classes</a>\n",
    "1. <a href=\"#named-arguments\">Named Arguments</a>\n",
    "1. <a href=\"#initial-values\">Initial Values</a>\n",
    "1. <a href=\"#variable-traces\">Variable Traces</a>\n",
    "1. <a href=\"#named-outputs\">Named Outputs</a>\n",
    "1. <a href=\"#enforcing-interfaces\">Enforcing Interfaces</a>\n",
    "1. <a href=\"#fixed-arguments\">Fixed Arguments</a>\n",
    "1. <a href=\"#scan\">Looping with Scan</a>\n",
    "1. <a href=\"#done\">Done</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='symbolic-functions'></a>\n",
    "## 1. Symbolic Functions.\n",
    "\n",
    "In Plato, we have the concept of *symbolic functions*, which are function that take and return theano symbolic variables.  These functions can be compiled to *numeric functions* which take and return numpy arrays and python ints/floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3+4=7\n"
     ]
    }
   ],
   "source": [
    "from plato.core import symbolic\n",
    "\n",
    "@symbolic\n",
    "def add_two_numbers(x, y):\n",
    "    return x+y\n",
    "\n",
    "f = add_two_numbers.compile()\n",
    "print '3+4=%s' % f(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, here is what happens: On the first (and in this case, only) call to add_two_numbers, Plato inspects the inputs (3, 4), looks at their type (both scalar integers in this case), and gets Theano to compile a symbolic expression that adds them together.  The equivalent code using just theano would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3+4=7\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano.tensor import scalar\n",
    "\n",
    "x = scalar(dtype = 'int32')\n",
    "y = scalar(dtype = 'int32')\n",
    "z = x+y\n",
    "\n",
    "f = theano.function(inputs = [x, y], outputs = z)\n",
    "print '3+4=%s' % f(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the first advantage of Plato is that it removes the need to create input variables and make sure their type matches the data that you're going to feed in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='adding-state'></a>\n",
    "## 2. Adding State\n",
    "\n",
    "We are also able to create stateful functions.  Unlike Theano, we do not pass state-updates in the return value.  Instead, we call the function `add_update(shared_var, new_value)`.  The following example shows how to make a \"function\" with some internal state that updates on each call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can count to ten.  See: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "I can too: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "from plato.core import symbolic, add_update, create_shared_variable\n",
    "\n",
    "@symbolic\n",
    "def counter():\n",
    "    count = create_shared_variable(0)  # Create a shared variable, initialized at zero, which stores the count.\n",
    "    new_count = count+1\n",
    "    add_update(count, new_count)\n",
    "    return new_count\n",
    "\n",
    "f = counter.compile()\n",
    "print 'I can count to ten.  See: %s' % ([int(f()) for _ in xrange(10)])\n",
    "\n",
    "f2 = counter.compile()\n",
    "print 'I can too: %s' % ([int(f2()) for _ in xrange(10)])\n",
    "# Note that we start from scratch when we compile the function a new time, \n",
    "# because the shared variable is initialized within the function call.  If we\n",
    "# had declaired counter outside the function, the second count would run from \n",
    "# 11 to 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classes'></a>\n",
    "## 3. Classes: Multiple functions sharing a variable.\n",
    "\n",
    "We often have situations where we have a variable that is shared between two functions (e.g. in a classifier, the weights may be modified by the *train* function and used by the *predict* function).  As a simple example, we will train an online linear-regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-Cost at epoch 0.0: 71.0957337414\n",
      "Test-Cost at epoch 0.2: 1.80531974613\n",
      "Test-Cost at epoch 0.4: 0.171461641249\n",
      "Test-Cost at epoch 0.6: 0.0534058746453\n",
      "Test-Cost at epoch 0.8: 0.0513930637533\n",
      "Test-Cost at epoch 1.0: 0.0479122217093\n",
      "Test-Cost at epoch 1.2: 0.049664895374\n",
      "Test-Cost at epoch 1.4: 0.04996181797\n",
      "Test-Cost at epoch 1.6: 0.0530149365254\n",
      "Test-Cost at epoch 1.8: 0.0512821567434\n",
      "Test-Cost at epoch 2.0: 0.0479423388957\n"
     ]
    }
   ],
   "source": [
    "from plato.core import create_shared_variable, symbolic, add_update\n",
    "import theano.tensor as tt\n",
    "import numpy as np\n",
    "\n",
    "# Set up parameters\n",
    "n_in = 20\n",
    "n_out = 4\n",
    "n_training_samples = 500\n",
    "n_test_samples = 500\n",
    "n_epochs = 2\n",
    "noise = 0.1\n",
    "random_seed = 1234\n",
    "score_report_period = 100\n",
    "\n",
    "# Create a regression dataset\n",
    "rng = np.random.RandomState(random_seed)\n",
    "w_true = rng.randn(n_in, n_out)  # (n_in, n_out)\n",
    "training_data = rng.randn(n_training_samples, n_in)  # (n_training_samples, n_in)\n",
    "training_target = training_data.dot(w_true) + noise*rng.randn(n_training_samples, n_out)  # (n_training_samples, n_out)\n",
    "test_data = rng.randn(n_test_samples, n_in)  # (n_test_samples, n_in)\n",
    "test_target = test_data.dot(w_true) + noise*rng.randn(n_test_samples, n_out)  # (n_test_samples, n_out)\n",
    "\n",
    "# Create a linear regressor\n",
    "class LinearRegressor:\n",
    "\n",
    "    def __init__(self, n_in, n_out, eta = 0.01):\n",
    "        self.w = create_shared_variable(np.zeros((n_in, n_out)))\n",
    "        self.eta = eta\n",
    "\n",
    "    @symbolic\n",
    "    def train(self, x, targ):  # x: (n_samples, n_in), targ: (n_samples, n_out)\n",
    "        y = self.predict(x)\n",
    "        cost = ((targ - y)**2).sum(axis=1).mean(axis=0)\n",
    "        add_update(self.w, self.w - self.eta*tt.grad(cost=cost, wrt=self.w))\n",
    "\n",
    "    @symbolic\n",
    "    def predict(self, x):  # x: (n_samples, n_in)\n",
    "        return x.dot(self.w)\n",
    "\n",
    "# Setup the predictor and compile functions\n",
    "predictor = LinearRegressor(n_in, n_out)\n",
    "f_train = predictor.train.compile()\n",
    "f_predict = predictor.predict.compile()\n",
    "\n",
    "# Train on one sample at a time and periodically report score.\n",
    "for i in xrange(n_training_samples*n_epochs+1):\n",
    "    if i % score_report_period == 0:\n",
    "        out = f_predict(test_data)\n",
    "        test_cost = ((test_target-out)**2).sum(axis=1).mean(axis=0)\n",
    "        print 'Test-Cost at epoch %s: %s' % (float(i)/n_training_samples, test_cost)\n",
    "    f_train(training_data[[i % n_training_samples]], training_target[[i % n_training_samples]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=callable-classes></a>\n",
    "## 4. Callable Classes\n",
    "\n",
    "In Python, classes can also act as functions, if they implement a `__call__` method.  This can be useful when you want to make parameterized functions.  Therefore Plato also allows you to decorate callable classes.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3*4=12\n"
     ]
    }
   ],
   "source": [
    "from plato.core import symbolic\n",
    "\n",
    "@symbolic\n",
    "class MultiplyBySomething:\n",
    "    \n",
    "    def __init__(self, what):\n",
    "        self.what = what\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return x*self.what\n",
    "    \n",
    "f = MultiplyBySomething(3).compile()\n",
    "\n",
    "print '3*4=%s' % f(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='named-arguments'></a>\n",
    "## 5. Named Arguments\n",
    "\n",
    "Unlike Theano, Plato allows you to pass inputs into compiled functions by name.  The only requirement is that you are consistent with their usage (if you call the function as `f(3, y=4)` the first, time, you cannot call it as `f(3, 4)` the next time, otherwise you will get an error.  See the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2+4)/3 = 2\n",
      "(1+3)/2 = 2\n",
      "Lets try again, but leave x as an unnamed arg...\n",
      "You were inconsistent - referenced x as a kwarg in the first call but not the second.\n"
     ]
    }
   ],
   "source": [
    "from plato.core import symbolic\n",
    "\n",
    "@symbolic\n",
    "def add_and_div(x, y, z):\n",
    "    return (x+y)/z\n",
    "\n",
    "f = add_and_div.compile()\n",
    "print '(2+4)/3 = %s' % f(x=4, y=2, z=3)\n",
    "print '(1+3)/2 = %s' % f(z=2, y=3, x=1)\n",
    "\n",
    "try:\n",
    "    print 'Lets try again, but leave x as an unnamed arg...'\n",
    "    f(2, y=4, z=3.)\n",
    "except KeyError as e:\n",
    "    print 'You were inconsistent - referenced x as a kwarg in the first call but not the second.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='initial-values'></a>\n",
    "## 6. Initial Values\n",
    "\n",
    "A big advantage of Plato is easier debugging.  There are two ways in which Plato helps you debug.  The first is what we call \"initial values\".\n",
    "\n",
    "Theano allows you to add \"test-values\" to your symbolic variables ([see tutorial](http://deeplearning.net/software/theano/tutorial/debug_faq.html)).  This helps to catch shape-errors when building the graph, instead of at run-time, where it is difficult to find the line of code that caused them.  However, it can be a bit of extra work for the programmer, because they have to manually attach test values to their variables.  Fortunately, since Plato compiles your functions on the first pass, it can attach test-values \"under the hood\".\n",
    "\n",
    "For example, lets look at a matrix multiplication, where we accidently get the shapes of our matrices wrong.  Since all inputs are given test values, we can easily track down the error - the traceback will lead back to the correct line.  This would not have been possible without test values, because the error would occur in the compiled code, which is no-longer linked to the source code.\n",
    "\n",
    "Plato attaches the following properties to all symbolic variables:  \n",
    "**`var.ival`** - The initial value of the variable (a numpy array or scalar)  \n",
    "**`var.ishape`** - The initial shape of the variable  \n",
    "**`var.indim`** - The initial number of dimensions of the variable  \n",
    "**`var.idtype`** - The initial dtype of the variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x-shape: (5, 4)\n",
      "w-shape: (3, 4)\n",
      "ValueError: shapes (5,4) and (3,4) not aligned: 4 (dim 1) != 3 (dim 0)\n",
      "Now we try again with the correct shape, and it succeeds.\n",
      "x-shape: (5, 4)\n",
      "w-shape: (4, 3)\n",
      "Success! y-shape: (5, 3)\n",
      "Note that if we run again we print nothing because the symbolic function is just run once, on the first pass.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from plato.core import symbolic\n",
    "\n",
    "@symbolic\n",
    "def forward_pass(x, w):\n",
    "    print 'x-shape: %s' % (x.ishape, )\n",
    "    print 'w-shape: %s' % (w.ishape, )\n",
    "    # Note that the above test-values only display on the first iteration.\n",
    "    y = x.dot(w)\n",
    "    print 'Success! y-shape: %s' % (y.ishape, )\n",
    "    return y\n",
    "\n",
    "f = forward_pass.compile()\n",
    "\n",
    "try:\n",
    "    # The following will cause an error (because second argument should have shape (4, 3))\n",
    "    h = f(np.random.randn(5, 4), np.random.rand(3, 4))  \n",
    "except ValueError as err:\n",
    "    # If you do not catch the error, you get a stacktrace which points to the line at fault.\n",
    "    print '%s: %s' % (err.__class__.__name__, err.message)\n",
    "print \"Now we try again with the correct shape, and it succeeds.\"\n",
    "h = f(np.random.randn(5, 4), np.random.rand(4, 3))  \n",
    "print \"Note that if we run again we print nothing because the symbolic function is just run once, on the first pass.\"\n",
    "h = f(np.random.randn(5, 4), np.random.rand(4, 3))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial values can also be used to initialize shared variables.   You may want to initialize a shared variable to be the same size as another variable in the graph.  You could than say `shared_var = theano.shared(np.zeros(var.ishape))`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='variable-traces'></a>\n",
    "## 7: Debugging with Variable Traces\n",
    "\n",
    "We can use **`var.ival`** (see part 6, above) and its brothers to access variable values on the first pass, but what if we want to view variable values every time the function is called?  Ordinarily in Theano, this would require setting those variables as outputs, and restructuring code to peek at what would normally be an internal variables.  Plato does a bit of magic which allows you to print/plot/do anything with internal variables.  The following example illustrates this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Sigmoid Activation: [ 0.78945982  0.53619194 -0.43049064]\n",
      "Post-Sigmoid Activation: [ 0.68771535  0.63092613  0.39400917]\n",
      "===\n",
      "Pre-Sigmoid Activation: [ 4.70563364 -3.31114626 -0.67634189]\n",
      "Post-Sigmoid Activation: [ 0.99103689  0.03519078  0.33707824]\n",
      "===\n",
      "Pre-Sigmoid Activation: [-0.96537077  1.22738814 -0.3202669 ]\n",
      "Post-Sigmoid Activation: [ 0.27580416  0.77336109  0.4206107 ]\n",
      "===\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from plato.core import symbolic, tdbprint, create_shared_variable\n",
    "import theano.tensor as tt\n",
    "\n",
    "class Layer:\n",
    "    \n",
    "    def __init__(self, w):\n",
    "        self.w = create_shared_variable(w)\n",
    "        \n",
    "    @symbolic\n",
    "    def forward_pass(self, x):\n",
    "        pre_sigmoid = x.dot(self.w)\n",
    "        tdbprint(pre_sigmoid, name = 'Pre-Sigmoid Activation')  # Here we make a trace of an internal variable\n",
    "        y = tt.nnet.sigmoid(pre_sigmoid)\n",
    "        tdbprint(y, name = 'Post-Sigmoid Activation')  # Here we make a trace of an internal variable\n",
    "        return y\n",
    "    \n",
    "n_in = 4\n",
    "n_out = 3\n",
    "\n",
    "rng = np.random.RandomState(seed=1234)\n",
    "layer = Layer(rng.randn(n_in, n_out))\n",
    "fwd_fcn = layer.forward_pass.compile()\n",
    "for _ in xrange(3):\n",
    "    y = fwd_fcn(rng.randn(n_in))\n",
    "    print '==='"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='named-outputs'></a>\n",
    "## 8. Named outputs\n",
    "\n",
    "You can also return a dictionary of named outputs.  To demonstrate this, we can take the previous example, and instead of printing the pre-sigmoid as a debug value, we return in an output dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: [ 0.68771535  0.63092613  0.39400917]\n",
      "pre-sigmoid: [ 0.78945982  0.53619194 -0.43049064]\n",
      "====\n",
      "output: [ 0.99103689  0.03519078  0.33707824]\n",
      "pre-sigmoid: [ 4.70563364 -3.31114626 -0.67634189]\n",
      "====\n",
      "output: [ 0.27580416  0.77336109  0.4206107 ]\n",
      "pre-sigmoid: [-0.96537077  1.22738814 -0.3202669 ]\n",
      "====\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from plato.core import symbolic, tdbprint, create_shared_variable\n",
    "import theano.tensor as tt\n",
    "\n",
    "class Layer:\n",
    "    \n",
    "    def __init__(self, w):\n",
    "        self.w = create_shared_variable(w)\n",
    "        \n",
    "    @symbolic\n",
    "    def forward_pass(self, x):\n",
    "        pre_sigmoid = x.dot(self.w)\n",
    "        y = tt.nnet.sigmoid(pre_sigmoid)\n",
    "        return {'pre-sigmoid': pre_sigmoid, 'output': y}\n",
    "    \n",
    "n_in = 4\n",
    "n_out = 3\n",
    "    \n",
    "rng = np.random.RandomState(seed=1234)\n",
    "layer = Layer(rng.randn(n_in, n_out))\n",
    "fwd_fcn = layer.forward_pass.compile()\n",
    "for _ in xrange(3):\n",
    "    result = fwd_fcn(rng.randn(n_in))\n",
    "    for k, v in result.iteritems():\n",
    "        print '%s: %s' % (k, v)\n",
    "    print '===='\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to store and retrieve internal variable values, you can use **`tdb_trace`**, and **`get_tdb_traces`** in `plato.core`.\n",
    "\n",
    "You can also create live plots of internal variables using the function **`tdbplot`** in `plato.tools.tdb_plotting`, but this tutorial does not cover it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='enforcing-interfaces'></a>\n",
    "## 9. Enforcing Interfaces\n",
    "\n",
    "In larger programs, it can be useful to enforce interfaces - that is, functions are required to obey a certain contract.  This allows function A to use function B without knowing in particular which function it is - just that it takes inputs and returns outputs in some specified format.  For instance, you may have some code that iterates through a dataset and trains a predictor, but doesn't necessarily know what kind of predictor it is - just that it has a *train* function that accepts inputs and targets, updates some internal state variable.\n",
    "\n",
    "For this reason, we have an extended set of decorators which enforce type-checking on inputs, outputs, and updates.  \n",
    "\n",
    "**`@symbolic`** - No format requirements.  \n",
    "**`@symbolic_simple`** - Returns a single output variable.  \n",
    "**`@symbolic_multi`** - Returns a tuple of output tensors.  \n",
    "**`@symbolic_stateless`** - Makes no state updates.  \n",
    "**`@symbolic_updater`** - Returns nothing and produces at least one state update.  \n",
    "**`@symbolic_named_output`** - Returns a dictionary of named outputs\n",
    "\n",
    "To make custom function con you can decorate with **`@SymbolicFunction(input_format, output_format, update_format)`**, where each of the arguments is an `IFormat` object.  See `plato.core` for examples.\n",
    "\n",
    "When functions fail to obey the contract specified by their decorators, a `SymbolicFormatError` is raised.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to run incorrectly-decorated function...\n",
      "  SymbolicFormatError: Function <function running_sum at 0x107a61cf8> should have created no state updates, but it created updates: [(<TensorType(int64, scalar)>, Elemwise{add,no_inplace}.0)]\n",
      "Lets try again with the correct format....\n",
      "  cumsum([1,2,3,4]) = [1, 3, 6, 10]\n"
     ]
    }
   ],
   "source": [
    "from plato.core import symbolic_stateless, symbolic, SymbolicFormatError, add_update, create_shared_variable\n",
    "\n",
    "@symbolic_stateless # Bad! We decorated with \"symbolic_stateless\", but we make a state update inside\n",
    "def running_sum(x):\n",
    "    shared_var = create_shared_variable(0)\n",
    "    y = x + shared_var\n",
    "    add_update(shared_var, y) \n",
    "    return y \n",
    "\n",
    "f = running_sum.compile()\n",
    "print 'Trying to run incorrectly-decorated function...'\n",
    "try: \n",
    "    f(3)\n",
    "except SymbolicFormatError as err:\n",
    "    print '  %s: %s' % (err.__class__.__name__, err.message)\n",
    "\n",
    "print 'Lets try again with the correct format....'\n",
    "\n",
    "@symbolic\n",
    "def running_sum(x):\n",
    "    shared_var = create_shared_variable(0)\n",
    "    y = x + shared_var\n",
    "    add_update(shared_var, y) \n",
    "    return y \n",
    "\n",
    "f = running_sum.compile()\n",
    "\n",
    "print '  cumsum([1,2,3,4]) = %s' % ([int(f(i)) for i in xrange(1, 5)], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fixed-arguments'></a>\n",
    "## 10. Fixed Arguments\n",
    "\n",
    "When you use a numpy array on a theano symbolic function, it treats it as a constant.  We can use the **fixed_args** argument to **compile()** to partially-specify a function.  Theano will then compile the function with these arguments as fixed constants.  For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3*2 = 6\n",
      "3*5 = 15\n"
     ]
    }
   ],
   "source": [
    "from plato.core import symbolic\n",
    "\n",
    "@symbolic\n",
    "def multiply(x, y):\n",
    "    return x*y\n",
    "\n",
    "f_mult_by_3 = multiply.compile(fixed_args = dict(x=3))\n",
    "\n",
    "print '3*2 = %s' % f_mult_by_3(y=2)\n",
    "print '3*5 = %s' % f_mult_by_3(y=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scan'></a>\n",
    "## 11. Looping with scan\n",
    "\n",
    "For looping operations in Theano, there is the **`scan`** function.  In Plato, symbolic functions have a **`.scan`** method of their own that you can call to output the result of the given function when called in a loop with updates applied sequentially and the return values piled into an array.  The arguments have all the same names and semantics as Theano's scan function, so see Theano's [scan documentation](http://deeplearning.net/software/theano/library/scan.html) for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cumsum of [1,2,3,4]: [ 1  3  6 10]\n",
      "Continuing Running Cumsum of [1,2,3,4]: [11 13 16 20]\n"
     ]
    }
   ],
   "source": [
    "from plato.core import symbolic, create_shared_variable, add_update\n",
    "import numpy as np\n",
    "\n",
    "@symbolic\n",
    "def running_sum(x):\n",
    "    shared_var = create_shared_variable(0)\n",
    "    y = x + shared_var\n",
    "    add_update(shared_var, y) \n",
    "    return y \n",
    "\n",
    "@symbolic\n",
    "def running_cumsum(arr):\n",
    "    cumsum = running_sum.scan(sequences = [arr])\n",
    "    return cumsum\n",
    "\n",
    "f = running_cumsum.compile()\n",
    "\n",
    "print 'Running Cumsum of [1,2,3,4]: %s' % (f(np.arange(1, 5)), )\n",
    "print 'Continuing Running Cumsum of [1,2,3,4]: %s' % (f(np.arange(1, 5)), )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='done'></a>\n",
    "## 12. Done\n",
    "\n",
    "Congratulations.  You've completed the 12-step program and you're ready to use Plato.  You may now want to see examples of various [Learning Algorithms in Plato](https://github.com/petered/plato/wiki/Algorithms-in-Plato)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
